{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load a model\n",
    "modelpose = YOLO('yolov8n-pose.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 46\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boxing' 'jumping' 'running' 'sitting' 'squat' 'standing' 'walking']\n"
     ]
    }
   ],
   "source": [
    "# Define path to the main folder containing class subfolders\n",
    "data_path = \"C:\\\\Users\\\\ag701\\\\Desktop\\\\lstm\\\\LSTM\\\\MP_Data\"  # Replace with your actual path\n",
    "\n",
    "# Define actions based on subfolder names (modify as needed)\n",
    "actions = np.array(os.listdir(data_path))  # Get list of subfolders\n",
    "print(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(15,34)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action83.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245), (126, 249, 255), (255, 166, 255),(16,117,245), (40, 166, 133)]\n",
    "def prob_viz(res, actions, input_frame, colors, keypoints):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    top_left_x = int(keypoints[0][:, 0].min().item())  # Minimum x-coordinate across all keypoints\n",
    "    top_left_y = int(keypoints[0][:, 1].min().item())-20  # Minimum y-coordinate across all keypoints\n",
    "    bottom_right_x = int(keypoints[0][:, 0].max().item())  # Maximum x-coordinate across all keypoints\n",
    "    bottom_right_y = int(keypoints[0][:, 1].max().item())+20 # Maximum y-coordinate across all keypoints\n",
    "\n",
    "    # Define bounding box thickness and color\n",
    "    thickness = 2\n",
    "    color = (0, 255, 0)  # Green for bounding box\n",
    "\n",
    "    # Draw the rectangle\n",
    "    cv2.rectangle(output_frame, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, thickness)\n",
    "\n",
    "    return output_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. New detection variables\n",
    "# import cv2\n",
    "# sequence = []\n",
    "# sentence = []\n",
    "# threshold = 0.6\n",
    "\n",
    "# cap = cv2.VideoCapture(\"Dataset/jumping/6032918-hd_1920_1080_25fps.mp4\")\n",
    "# # Set mediapipe model \n",
    "\n",
    "# while cap.isOpened():\n",
    "\n",
    "#     # Read feed\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     if not ret:\n",
    "#         print(\"No frames left in video. Exiting...\")\n",
    "#         break\n",
    "    \n",
    "#     image = frame\n",
    "\n",
    "#     # Make detections\n",
    "#     results = modelpose.predict(frame)\n",
    "#     # Flatten keypoints\n",
    "#     # keypoints = np.array(results[0][0].keypoints.xy).flatten()\n",
    "#     for r in results:\n",
    "#         keypoints = np.array(r.keypoints.xy).flatten()  # Extract keypoints\n",
    "        \n",
    "    \n",
    "\n",
    "#     sequence.append(keypoints)\n",
    "#     sequence = sequence[-15:]\n",
    "    \n",
    "#     if len(sequence) == 15:\n",
    "#         res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "#         print(actions[np.argmax(res)])\n",
    "        \n",
    "        \n",
    "#     #3. Viz logic\n",
    "#         if res[np.argmax(res)] > threshold: \n",
    "#             if len(sentence) > 0: \n",
    "#                 if actions[np.argmax(res)] != sentence[-1]:\n",
    "#                     sentence.append(actions[np.argmax(res)])\n",
    "#             else:\n",
    "#                 sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "#         if len(sentence) > 5: \n",
    "#             sentence = sentence[-5:]\n",
    "\n",
    "        \n",
    "#     cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "#     cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "#     # Show to screen\n",
    "#     cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "#     # Break gracefully\n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 119.0ms\n",
      "Speed: 5.0ms preprocess, 119.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 134.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 134.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 106.4ms\n",
      "Speed: 3.0ms preprocess, 106.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 105.9ms\n",
      "Speed: 3.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 99.8ms\n",
      "Speed: 1.0ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 98.7ms\n",
      "Speed: 0.9ms preprocess, 98.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 81.3ms\n",
      "Speed: 2.9ms preprocess, 81.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 97.5ms\n",
      "Speed: 3.1ms preprocess, 97.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 79.2ms\n",
      "Speed: 3.1ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 78.7ms\n",
      "Speed: 3.0ms preprocess, 78.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 99.4ms\n",
      "Speed: 3.9ms preprocess, 99.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 77.6ms\n",
      "Speed: 4.0ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 96.2ms\n",
      "Speed: 1.6ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 103.7ms\n",
      "Speed: 3.0ms preprocess, 103.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 85.9ms\n",
      "Speed: 1.9ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 98.5ms\n",
      "Speed: 0.0ms preprocess, 98.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 122.8ms\n",
      "Speed: 2.9ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 92.6ms\n",
      "Speed: 1.8ms preprocess, 92.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 90.1ms\n",
      "Speed: 2.6ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 94.5ms\n",
      "Speed: 1.5ms preprocess, 94.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 83.6ms\n",
      "Speed: 0.0ms preprocess, 83.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 97.2ms\n",
      "Speed: 0.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 84.1ms\n",
      "Speed: 0.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 84.1ms\n",
      "Speed: 0.0ms preprocess, 84.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 114.6ms\n",
      "Speed: 0.0ms preprocess, 114.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.3ms\n",
      "Speed: 2.0ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 86.6ms\n",
      "Speed: 0.0ms preprocess, 86.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.0ms\n",
      "Speed: 1.8ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 91.1ms\n",
      "Speed: 2.3ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 93.0ms\n",
      "Speed: 0.0ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 83.7ms\n",
      "Speed: 0.0ms preprocess, 83.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 99.0ms\n",
      "Speed: 0.0ms preprocess, 99.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 127.0ms\n",
      "Speed: 0.0ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 83.0ms\n",
      "Speed: 0.0ms preprocess, 83.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 99.8ms\n",
      "Speed: 0.0ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 102.0ms\n",
      "Speed: 0.0ms preprocess, 102.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.3ms\n",
      "Speed: 0.0ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 86.2ms\n",
      "Speed: 0.0ms preprocess, 86.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 124.1ms\n",
      "Speed: 0.0ms preprocess, 124.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 127.3ms\n",
      "Speed: 2.0ms preprocess, 127.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 89.4ms\n",
      "Speed: 2.0ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 100.4ms\n",
      "Speed: 0.0ms preprocess, 100.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 91.5ms\n",
      "Speed: 2.0ms preprocess, 91.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 99.7ms\n",
      "Speed: 0.0ms preprocess, 99.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 89.6ms\n",
      "Speed: 2.1ms preprocess, 89.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 123.3ms\n",
      "Speed: 2.0ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 99.1ms\n",
      "Speed: 0.0ms preprocess, 99.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.3ms\n",
      "Speed: 1.9ms preprocess, 95.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 98.4ms\n",
      "Speed: 0.0ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 95.3ms\n",
      "Speed: 1.3ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 81.6ms\n",
      "Speed: 2.7ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 92.8ms\n",
      "Speed: 0.0ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 147.6ms\n",
      "Speed: 0.0ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 92.8ms\n",
      "Speed: 2.0ms preprocess, 92.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 88.7ms\n",
      "Speed: 3.0ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 89.2ms\n",
      "Speed: 1.0ms preprocess, 89.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.0ms\n",
      "Speed: 0.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 97.9ms\n",
      "Speed: 2.5ms preprocess, 97.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 92.0ms\n",
      "Speed: 2.0ms preprocess, 92.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 128.8ms\n",
      "Speed: 0.0ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.9ms\n",
      "Speed: 2.1ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 106.8ms\n",
      "Speed: 0.0ms preprocess, 106.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 81.6ms\n",
      "Speed: 1.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 101.5ms\n",
      "Speed: 2.0ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 100.4ms\n",
      "Speed: 2.0ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.8ms\n",
      "Speed: 2.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 139.5ms\n",
      "Speed: 0.0ms preprocess, 139.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "running"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 119.1ms\n",
      "Speed: 2.1ms preprocess, 119.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 113.8ms\n",
      "Speed: 3.0ms preprocess, 113.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "squat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 102.2ms\n",
      "Speed: 1.8ms preprocess, 102.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "squat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 100.3ms\n",
      "Speed: 2.1ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 111.0ms\n",
      "Speed: 0.0ms preprocess, 111.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 91.7ms\n",
      "Speed: 2.1ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 116.2ms\n",
      "Speed: 1.0ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 122.8ms\n",
      "Speed: 2.0ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 122.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.8ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.6ms\n",
      "Speed: 2.0ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 104.2ms\n",
      "Speed: 2.0ms preprocess, 104.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 104.5ms\n",
      "Speed: 2.4ms preprocess, 104.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 999us/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 118.8ms\n",
      "Speed: 2.0ms preprocess, 118.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 145.3ms\n",
      "Speed: 0.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 90.2ms\n",
      "Speed: 2.0ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 110.9ms\n",
      "Speed: 2.1ms preprocess, 110.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 92.3ms\n",
      "Speed: 2.0ms preprocess, 92.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.6ms\n",
      "Speed: 2.0ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 102.3ms\n",
      "Speed: 2.0ms preprocess, 102.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 106.0ms\n",
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 123.5ms\n",
      "Speed: 1.6ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 113.0ms\n",
      "Speed: 2.0ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 110.1ms\n",
      "Speed: 1.7ms preprocess, 110.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.5ms\n",
      "Speed: 1.1ms preprocess, 97.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 105.8ms\n",
      "Speed: 1.0ms preprocess, 105.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 97.2ms\n",
      "Speed: 1.9ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 99.4ms\n",
      "Speed: 2.0ms preprocess, 99.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 105.2ms\n",
      "Speed: 2.0ms preprocess, 105.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 107.4ms\n",
      "Speed: 4.1ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 104.3ms\n",
      "Speed: 0.0ms preprocess, 104.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 101.1ms\n",
      "Speed: 2.6ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 106.4ms\n",
      "Speed: 0.0ms preprocess, 106.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 117.9ms\n",
      "Speed: 2.1ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 109.0ms\n",
      "Speed: 2.3ms preprocess, 109.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 90.0ms\n",
      "Speed: 1.0ms preprocess, 90.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 97.8ms\n",
      "Speed: 2.0ms preprocess, 97.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 134.6ms\n",
      "Speed: 2.3ms preprocess, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 112.0ms\n",
      "Speed: 1.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 94.8ms\n",
      "Speed: 2.1ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 126.7ms\n",
      "Speed: 0.0ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "boxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.4ms\n",
      "Speed: 2.0ms preprocess, 93.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 100.7ms\n",
      "Speed: 2.0ms preprocess, 100.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 124.9ms\n",
      "Speed: 2.0ms preprocess, 124.9ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 102.0ms\n",
      "Speed: 0.0ms preprocess, 102.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 101.0ms\n",
      "Speed: 2.1ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 104.0ms\n",
      "Speed: 2.1ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 101.1ms\n",
      "Speed: 1.6ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 98.4ms\n",
      "Speed: 2.3ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 105.4ms\n",
      "Speed: 4.2ms preprocess, 105.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 95.6ms\n",
      "Speed: 2.0ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 128.3ms\n",
      "Speed: 1.5ms preprocess, 128.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 114.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.5ms\n",
      "Speed: 2.0ms preprocess, 97.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 107.4ms\n",
      "Speed: 2.2ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 111.4ms\n",
      "Speed: 2.0ms preprocess, 111.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 139.8ms\n",
      "Speed: 0.0ms preprocess, 139.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 140.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 140.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 113.6ms\n",
      "Speed: 2.4ms preprocess, 113.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 93.2ms\n",
      "Speed: 1.0ms preprocess, 93.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 104.6ms\n",
      "Speed: 2.0ms preprocess, 104.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 100.8ms\n",
      "Speed: 1.6ms preprocess, 100.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 104.7ms\n",
      "Speed: 2.0ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 113.9ms\n",
      "Speed: 0.0ms preprocess, 113.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 94.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 94.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 105.7ms\n",
      "Speed: 2.0ms preprocess, 105.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 103.3ms\n",
      "Speed: 2.0ms preprocess, 103.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 115.1ms\n",
      "Speed: 1.7ms preprocess, 115.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 109.4ms\n",
      "Speed: 0.0ms preprocess, 109.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 106.7ms\n",
      "Speed: 1.0ms preprocess, 106.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 109.3ms\n",
      "Speed: 4.0ms preprocess, 109.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 106.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 106.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 111.4ms\n",
      "Speed: 0.0ms preprocess, 111.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 88.1ms\n",
      "Speed: 2.7ms preprocess, 88.1ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 96.1ms\n",
      "Speed: 2.0ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 108.5ms\n",
      "Speed: 1.0ms preprocess, 108.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.1ms\n",
      "Speed: 0.8ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 132.7ms\n",
      "Speed: 2.0ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 94.2ms\n",
      "Speed: 2.0ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 125.9ms\n",
      "Speed: 0.0ms preprocess, 125.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 125.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 126.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.6ms preprocess, 126.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 127.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 127.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 119.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 119.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 153.2ms\n",
      "Speed: 2.0ms preprocess, 153.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 136.1ms\n",
      "Speed: 3.0ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 146.7ms\n",
      "Speed: 0.0ms preprocess, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 135.2ms\n",
      "Speed: 2.0ms preprocess, 135.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 138.5ms\n",
      "Speed: 1.6ms preprocess, 138.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 143.4ms\n",
      "Speed: 4.0ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 141.6ms\n",
      "Speed: 2.0ms preprocess, 141.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 138.5ms\n",
      "Speed: 2.0ms preprocess, 138.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 139.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 139.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 161.5ms\n",
      "Speed: 0.0ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 135.0ms\n",
      "Speed: 3.1ms preprocess, 135.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 125.0ms\n",
      "Speed: 2.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 132.3ms\n",
      "Speed: 3.0ms preprocess, 132.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 104.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.6ms preprocess, 104.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 110.9ms\n",
      "Speed: 2.0ms preprocess, 110.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 115.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.5ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 101.5ms\n",
      "Speed: 1.0ms preprocess, 101.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 114.1ms\n",
      "Speed: 0.0ms preprocess, 114.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 101.2ms\n",
      "Speed: 0.0ms preprocess, 101.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 101.6ms\n",
      "Speed: 0.0ms preprocess, 101.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 98.4ms\n",
      "Speed: 2.0ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 4 persons, 113.4ms\n",
      "Speed: 0.0ms preprocess, 113.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 114.9ms\n",
      "Speed: 0.0ms preprocess, 114.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 115.3ms\n",
      "Speed: 0.0ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 5 persons, 120.6ms\n",
      "Speed: 0.0ms preprocess, 120.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 105.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.9ms preprocess, 105.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 112.7ms\n",
      "Speed: 0.0ms preprocess, 112.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 101.2ms\n",
      "Speed: 0.0ms preprocess, 101.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 95.2ms\n",
      "Speed: 0.0ms preprocess, 95.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 149.6ms\n",
      "Speed: 0.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 101.4ms\n",
      "Speed: 0.0ms preprocess, 101.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 100.0ms\n",
      "Speed: 0.0ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.9ms\n",
      "Speed: 0.8ms preprocess, 97.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 83.3ms\n",
      "Speed: 0.2ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 96.3ms\n",
      "Speed: 2.1ms preprocess, 96.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 85.7ms\n",
      "Speed: 3.6ms preprocess, 85.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 95.6ms\n",
      "Speed: 2.8ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 144.9ms\n",
      "Speed: 1.0ms preprocess, 144.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 108.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 108.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 99.2ms\n",
      "Speed: 0.0ms preprocess, 99.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 113.8ms\n",
      "Speed: 0.0ms preprocess, 113.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([6, 17, 2])\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 104.4ms\n",
      "Speed: 0.0ms preprocess, 104.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxing\n",
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 97.6ms\n",
      "Speed: 0.0ms preprocess, 97.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "boxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 101.1ms\n",
      "Speed: 0.0ms preprocess, 101.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keypoints torch.Size([4, 17, 2])\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "boxing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 99.9ms\n",
      "Speed: 0.0ms preprocess, 99.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoints torch.Size([5, 17, 2])\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "boxing\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.6\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\\\ag701\\\\Desktop\\\\lstm\\\\LSTM\\\\walking2.mp4\")\n",
    "# Set mediapipe model \n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Read feed\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"No frames left in video. Exiting...\")\n",
    "        break\n",
    "    \n",
    "    image = frame\n",
    "\n",
    "    # Make detections\n",
    "    results = modelpose.predict(frame)\n",
    "    \n",
    "    keyframes = []\n",
    "    # # Flatten keypoints\n",
    "    keypointsn = np.array(results[0][0].keypoints.xyn).flatten()\n",
    "    \n",
    "    if len(keypointsn) == 0:\n",
    "            keypointsn = torch.zeros(1, 17, 2)\n",
    "            \n",
    "    for r in results:\n",
    "        keypoints=[]\n",
    "        keypoints = r.keypoints.xy\n",
    "        print(\"keypoints\", keypoints.shape)\n",
    "        # if len(keypoints) > 0:  # Check for missing keypoints (optional)\n",
    "        #     keyframes.append(keypoints)\n",
    "        if len(keypoints) == 0:\n",
    "            keypoints = torch.zeros(1, 17, 2)\n",
    "    # if len(keyframes) > 0:  # Check for empty frames (optional)\n",
    "    #     keyframes = np.array(keyframes).flatten()\n",
    "    #     sequence.append(keyframes[-1])\n",
    "    #     sequence = sequence[-15:]\n",
    "\n",
    "    sequence.append(keypointsn)\n",
    "    sequence = sequence[-15:]\n",
    "    \n",
    "    if len(sequence) == 15:\n",
    "        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "        print(actions[np.argmax(res)])\n",
    "        \n",
    "        \n",
    "    #3. Viz logic\n",
    "        if res[np.argmax(res)] > threshold: \n",
    "            if len(sentence) > 0: \n",
    "                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "            else:\n",
    "                sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "        if len(sentence) > 5: \n",
    "            sentence = sentence[-5:]\n",
    "\n",
    "        # Viz probabilities\n",
    "        image = prob_viz(res, actions, image, colors, keypoints)\n",
    "        \n",
    "    cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "    cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Show to screen\n",
    "    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
